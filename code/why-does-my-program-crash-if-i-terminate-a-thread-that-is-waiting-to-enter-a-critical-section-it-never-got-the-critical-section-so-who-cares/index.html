<body style=max-width:80ch;margin:auto>
<h1 class="entry-title" style="margin-bottom:15px;">Why does my program crash if I terminate a thread that is waiting to enter a critical section? It never got the critical section, so who cares?</h1>  <!-- .entry-meta -->

<p>A customer had a program that used the <code>Terminate­Thread</code> function to terminate a thread while it was waiting for a critical section. They claim that this code worked in earlier versions of Windows, but starting in Windows 10, the program crashes when it tries to use that critical section further. Why is this happening? The documentation for <code>Enter­Critical­Section</code> says</p>
<blockquote class="q"><p>If a thread terminates while it has ownership of a critical section, the state of the critical section is undefined.</p></blockquote>
<p>But it doesn’t say that there’s anything wrong with terminating a thread that is <i>waiting</i> for a critical section.</p>
<p>Well, yeah, it doesn’t say that because the only way you can get into that state is if you call <code>Terminate­Thread</code> while the <code>Enter­Critical­Section</code> is still running, and <a href="/history/windows-started-picking-up-the-really-big-pieces-of-terminatethread-garbage-on-the-sidewalk-but-it-s-still-garbage-on-the-sidewalk"> terminating a thread is already a terrible idea</a>. It’s such a terrible idea that doing so puts the entire process is an undefined state. There’s no point trying to go into the details of what could happen when your process is an undefined state. It’s undefined!</p>
<p>But just for curiosity’s sake, what changed in Windows 10 that made the undefined state lead to a crash?</p>
<p>Historically, critical sections were implemented in terms of an interlocked integer and a kernel event. The interlocked integer was used to keep track of the critical section’s state: Unowned, owned with no waiting threads, or owned with at least one waiting thread. If a thread needed to wait for the critical section, it waited on the kernel event handle. When the owner of the critical section exited it, it checked if there are any waiting threads, and if so, it signaled the event, thereby allowing one of the waiting threads to attempt to enter.</p>
<p>This design had some flaws. For example, a process that created lots of critical sections could potentially create a lot of kernel event handles, and kernel synchronization objects consume non-paged pool. To alleviate stress on non-paged pool, critical sections created the kernel event handle only on demand, but that introduces a new failure mode if the lazy creation of the kernel event handle fails. Some programs avoided this problem by pre-creating the kernel event handle, but that just put us back where we started with high non-paged-pool usage.</p>
<p>In Windows 10, critical sections were rewritten in terms of <code>Wait­On­Address</code>. This removes the need for kernel events entirely, and therefore avoids entire classes of potential problems.</p>
<p>The <code>Wait­On­Address</code> function works by linking the list of waiting threads through their stacks. This linked list of threads is manipulated both by waiting threads (when they join the list) and by the waking thread (so it can notify a waiting thread). The code to manipulate this linked list is quite complicated because it needs to do its work in a lock-free manner.¹</p>
<p>If you terminate a thread, the thread’s stack is cleaned up as part of cleaning up the biggest pieces of garbage on the sidewalk. That removes a memory leak, but it also leaves dangling pointers if that thread was calling <code>Wait­On­Address</code> or any other function that links memory on the stack into a data structure visible to other threads. And it’s those dangling pointers that cause any future use of the critical section to crash.</p>
<p><b>Bonus chatter</b>: If you think about it, the original design that allocated a kernel handle per critical section was wasteful. Really, you need one kernel handle per thread, since each thread can wait on only one critical section. (There is no <code>Wait­For­Multiple­Critical­Sections</code> function.) On the other hand, managing those kernel handles is complicated because you need to do it in a lock-free way. Once you sign up to do the complicated stuff, you may as well go all the way and do it handle-free.</p>
<p>¹ The slim reader-writer locks also links the list of waiting threads through their stacks. The code for slim read-writer locks is even more complicated because it needs to reorder the nodes within the linked list, while still being lock-free.</p>


</body>