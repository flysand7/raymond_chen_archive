<body style=max-width:80ch;margin:auto>
<h1 class="entry-title" style="margin-bottom:15px;">Don't trust the return address, no really</h1>  <!-- .entry-meta -->

<p>In the discussion of how to prevent non-“trusted” DLLs from using private OS resources, <a href="http://blogs.msdn.com/oldnewthing/archive/2005/10/26/485133.aspx#485654"> more than</a> <a href="http://blogs.msdn.com/oldnewthing/archive/2005/10/26/485133.aspx#485698"> one person</a> suggested having the <code>LoadLibrary</code> or <code>FindResource</code> function behave differently depending on who the caller is. But we already saw that <a href="http://blogs.msdn.com/oldnewthing/archive/2004/01/01/47042.aspx"> you can’t trust the return address</a> and that you definitely shouldn’t use the return address to make a security decision (which is what these people are proposing).
 All attackers have to do is find some other “trusted” code to do their dirty work. For example, the <code>LoadString</code> function internally calls <code>FindResource</code> to locate <a href="http://blogs.msdn.com/oldnewthing/archive/2004/01/30/65013.aspx"> the appropriate string bundle</a>. Therefore, if attackers want to get a string resource from a “trusted” DLL, they could use <code>LoadString</code> to do it, since <code>LoadString</code> will call <code>FindResource</code>, and <code>FindResource</code> will say, “Oh, my caller is <code>USER32.DLL</code>, which is trusted.” Bingo, they just stole a string resource.
 “Well, I could add that same check to <code>LoadString</code>.”
 I was just giving <code>LoadString</code> as an example of a “middle man” function that you can exploit. Sure, extra code could be added to <code>LoadString</code> to check its return address and reject attempts to load strings from “protected” libraries if the caller is “untrusted”, but attackers would just look for some other middle man they could exploit. And even if you were diligent enough to protect all such potential middle-men, you still are vulnerable to the sort of stack-manipulation games that don’t require anything from a “trusted” DLL aside from a return instruction. (And there are plenty of those.)
 No, you cannot impose security boundaries within a process. Once you let code run unchecked in your process, you have to treat the entire process as compromised. Even the parts that you thought were trustworthy.</p>
<p> Now, you might say, “Oh, we’re not really making a security decision here. We just want to make circumventing the system so much hard work that somebody who goes to that much effort knows that they’re doing something unsupported.” But <a href="http://blogs.msdn.com/oldnewthing/archive/2005/10/26/485133.aspx#485894"> as commenter Duncan Bayne points out</a>, that applies only to the first person to do it. They then make a library out of their technique, or publish it in a magazine article, and now anybody can use it without a struggle, and consequently without it crossing their mind that “Gosh, maybe this isn’t such a great idea to use in production software.” </p>


</body>