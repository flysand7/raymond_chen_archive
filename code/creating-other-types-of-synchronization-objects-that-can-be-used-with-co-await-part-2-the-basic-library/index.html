<body style=max-width:80ch;margin:auto>
<h1 class="entry-title" style="margin-bottom:15px;">Creating other types of synchronization objects that can be used with co_await, part 2: The basic library</h1>  <!-- .entry-meta -->

<p>Last time, I teased <a href="/code/creating-other-types-of-synchronization-objects-that-can-be-used-with-co-await-part-1-the-one-shot-event" title="Creating other types of synchronization objects that can be used with co_await, part 1"> a library for building awaitable synchronization objects</a>. It builds on the code had earlier written for one-shot events by distilling the pattern to its essence and then rebuilding it in a more generic way.</p>
<p>We start with the linked list nodes which are used to keep track of coroutines who are waiting for the synchronization object.</p>
<pre>namespace async_helpers::impl
{
    struct node_base
    {
        node_base* next;
        node_base* prev;
    };

    struct node_handle : node_base
    {
        std::experimental::coroutine_handle&lt;&gt; handle{};
    };

    template&lt;typename Extra&gt;
    struct node : node_handle
    {
        template&lt;typename... Args&gt;
        node(Args&amp;&amp;... args) :
            extra(std::forward&lt;Args&gt;(args)...) {}

        Extra extra;
    };
}
</pre>
<p>The <code>node_base</code> is the node for a doubly-linked list. Derived from that is a <code>node_handle</code> that also carries a coroutine handle payload, and further derived from that is a <code>node&lt;Extra&gt;</code> which allows us to attach other payload to the node.</p>
<p>Next comes the linked list of nodes:</p>
<pre>namespace async_helpers
{
    struct node_list : impl::node_base
    {
        node_list() : node_base{ this, this } {}
        node_list(node_list const&amp;) = delete;
        void operator=(node_list const&amp;) = delete;

        bool empty() const noexcept
        {
            return next == this;
        }

        void append_node(impl::node_base&amp; node) noexcept
        {
            node.next = this;
            node.prev = prev;
            prev-&gt;next = std::addressof(node);
            prev = std::addressof(node);
        }

        bool append_list(node_list&amp; other) noexcept
        {
            if (other.empty()) return false;
            other.prev-&gt;next = next;
            next-&gt;prev = other.prev;
            next = other.next;
            next-&gt;prev = this;
            other.next = other.prev = std::addressof(other);
            return true;
        }

        impl::node_base* peek_head() const noexcept
        {
            return empty() ? nullptr : next;
        }

        impl::node_base* try_remove_head() noexcept
        {
            if (empty()) return nullptr;
            auto node = next;
            next = node-&gt;next;
            next-&gt;prev = this;
            return node;
        }
    };
}
</pre>
<p>These are unexciting operations on doubly-linked lists. We have to write them ourselves because the C++ standard library uses non-intrusive linked lists, but we want intrusive linked lists to avoid the error conditions associated with memory allocation failures.</p>
<p>The node list is represented by a sentinel node that marks the beginning/end of the list. There is a little quirkiness in that I use <code>std::addressof</code> instead of the <code>&amp;</code> operator, out of an abundance of caution, in case somebody decides to overload the <code>&amp;</code> operator.</p>
<pre>namespace async_helpers
{
    // Specialize if you need extra data for co_await.
    template&lt;typename State&gt; struct extra_await_data {};
}
</pre>
<p>We provide a traits class that lets you attach extra information to your <code>awaiter</code> to record additional context about awaiting. This will come in handy when we try to implement reader/writer locks.</p>
<p>The real excitement is in our <code>state</code> object. The intended usage is that you derive your full state object from the basic one, and the basic one uses CRTP to allow your full state object to customize certain operations. Last time, we saw how we could use this pattern for a one-shot event.</p>
<p>We’ll look at the <code>awaitable_<wbr/>state</code> a little bit at a time.</p>
<pre>namespace async_helpers
{
    template&lt;typename State&gt;
    class awaitable_state
    {
        std::mutex mutex;
        node_list sentinel;

        State&amp; parent() { return static_cast&lt;State&amp;&gt;(*this); }

        auto&amp; extra_node(impl::node_base&amp; node)
        { static_cast&lt;impl::node&lt;extra_await_data&gt;&amp;&gt;(node); }
</pre>
<p>An awaitable object’s state consists of a list of waiting coroutines, protected by a mutex. The helper function <code>parent()</code> helps with CRPT by downcasting the <code>awaitable_<wbr/>state</code> to the full <code>State</code> object. Similarly, <code>extra_<wbr/>node</code> takes a <code>node_<wbr/>base</code> and downcasts it all the way to a <code>node&lt;extra_<wbr/>await_<wbr/>data&gt;</code> so we can access the full node complete with extra data.</p>
<pre>    public:
        using extra_await_data = extra_await_data&lt;State&gt;;
        using node_list = async_helpers::node_list;
</pre>
<p>For convenience, we give names to the extra data and the node list itself.</p>
<pre>        bool fast_claim(extra_await_data const&amp;) const noexcept
        { return false; }
</pre>
<p>The <code>fast_<wbr/>claim</code> method is optional. If the derived class doesn’t implement it, then we provide a default implementation that says “Nope, must do it the slow way.”</p>
<pre>        extra_await_data* peek_head() const noexcept
        {
            auto node = sentinel.peek_head();
            return node ? &amp;extra_node(node)-&gt;extra : nullptr;
        }
</pre>
<p>The derived class can use <code>peek_<wbr/>head</code> to peek at the extra data associated with the coroutine at the head of the wait list. If the wait list is empty, then the method returns <code>nullptr</code>. This method may be called only from within an action, since it requires that the lock be held.</p>
<p>Also from within an action, the derived class can ask for one waiting coroutine to be resumed:</p>
<pre>        bool resume_one(node_list&amp; list) noexcept
        {
            auto node = sentinel.try_remove_head();
            if (!node) return false;
            list.append_node(*node);
            return true;
        }
</pre>
<p>This is done by unlinking the head node from the waiting list and appending it to the resume list. We append to the tail of the resume list to preserve FIFO.</p>
<p>Another thing an action can do is ask for all of the waiting coroutines to be released.</p>
<pre>        bool resume_all(node_list&amp; list) noexcept
        {
            return list.append_list(sentinel);
        }
</pre>
<p>This is equivalent to calling <code>resume_one</code> in a loop until it fails, but we can do it more efficiently by moving the entire list at once.</p>
<p>When a coroutine awaits the synchronization object, we ask <code>await_<wbr/>suspend</code> to do the work:</p>
<pre>        bool await_suspend(
            std::experimental::coroutine_handle&lt;&gt; handle,
            impl::node&lt;extra_await_data&gt;&amp; node)
        {
            auto guard = std::lock_guard(mutex);
            if (parent().claim(node.extra)) return false;
            node.handle = handle;
            sentinel.append_node(node);
            return true;
        }
</pre>
<p>The caller provides a coroutine handle and a preallocated <code>node</code>. We enter the lock and try to claim the synchronization object. If successful, then we are done, and we return <code>false</code> to tell the coroutine machinery that the coroutine should resume immediately. Otherwise, we remember the coroutine handle and append the node to the list of waiters, returning <code>true</code> to complete the suspension.</p>
<pre>        void await_resume(
            impl::node&lt;extra_await_data&gt;&amp; node) noexcept
        {
            node.handle = nullptr;
        }
</pre>
<p>When the coroutine resumes, we null out the coroutine handle so that we know that the coroutine is no longer suspended and that we therefore are no longer in the cancellation case. I’ll discuss later why we do it in <code>await_resume</code>.</p>
<pre>        void destruct_node(impl::node_base&amp; node) noexcept
        {
            if (node.handle) {
                auto guard = std::lock_guard(mutex);
                node.next = node.prev-&gt;next;
                node.prev = node.next-&gt;prev;
            }
        }
</pre>
<p>This is part of our accommodation for cancellation: In the case that a waiting coroutine is destroyed, we check if it has a pending resumption handle. If so, then we are in the cancellation case, and we unlink it from the list of waiters. There is a race here: If the coroutine has already been scheduled for resumption, our attempt to unlink it will corrupt memory because the <code>prev</code> and <code>next</code> members of the node point to already-resumed coroutines. However, <!-- backref: Creating a <CODE>co_await</CODE> awaitable signal that can be awaited multiple times, part 6 --> as we discussed earlier, if this happens, then it means that the caller was already in a race condition, trying to destroy a coroutine as it is resuming. It is the caller’s responsibility to ensure that destroying a suspended coroutine happens only when it can guarantee that the coroutine is not at risk of resumption.¹</p>
<p>The next bit is the part that makes actions happen:</p>
<pre>        template&lt;typename... Params, typename... Args&gt;
        void action_impl(
            void (State::*handler)(node_list&amp;, Params...),
            Args&amp;&amp;... args)
        {
            node_list list;
            {
                auto guard = std::lock_guard(mutex);
                (parent().*handler)(list,
                    std::forward&lt;Args&gt;(args)...);
            }
            resume_list(list);
        }
</pre>
<p>We create an empty node list outside the lock, take the lock, and then call the handler, forwarding all the parameters. When the handler returns, we drop the lock and resume all the coroutines it had requested to be resumed, using this <code>resume_<wbr/>list</code> method:</p>
<pre>    private:
        void resume_list(node_list&amp; list)
        {
            auto node = list.next;
            while (node != std::addressof(list))
            {
                resume_node(std::exchange(node, node-&gt;next));
            }
        }

        void resume_node(impl::node_base* node) noexcept
        {
            extra_node(*node).handle.resume();
        }
    };
</pre>
<p>Resuming a list consists of calling <code>resume_<wbr/>node</code> on each node in the list. Note that the node is owned by the coroutine, so resuming the coroutine will cause the awaiter to be destructed, and the node will disappear with it. We therefore have to make sure that we do not touch the node after resuming the coroutine. In this case, it means that we advance to the <code>next</code> node and pull out the <code>handle</code> before resuming the handle.</p>
<p>This example resumes the coroutines synchronously. We’ll work on asynchronous resumption next time.</p>
<p>The last piece is defining the synchronization object itself:</p>
<pre>    template&lt;typename State&gt;
    class awaitable_sync_object
    {
        std::shared_ptr&lt;State&gt; shared;

    public:
        template&lt;typename... Args&gt;
        awaitable_sync_object(Args&amp;&amp;... args) :
            shared(std::make_shared&lt;State&gt;(
                std::forward&lt;Args&gt;(args)...)) {}

        template&lt;typename Arg = typename State::extra_await_data&gt;
        auto make_awaiter(Arg arg = {})
        { return awaiter{ *shared, std::forward&lt;Arg&gt;(arg) }; }

        auto operator co_await() { return awaiter{ *shared }; }

    protected:
        using state = State;

        State&amp; get_state() const noexcept { return *shared; }

        template&lt;typename... Args&gt;
        void action_impl(Args&amp;&amp;... args) const
        {
            shared-&gt;action_impl(std::forward&lt;Args&gt;(args)...);
        }

        struct awaiter
        {
            template&lt;typename... Args&gt;
            awaiter(State&amp; state, Args&amp;&amp;... args)
                : s(state), node(std::forward&lt;Args&gt;(args)...) {}

            State&amp; s;
            impl::node&lt;extra_await_data&lt;State&gt;&gt; node;

            bool await_ready()
            { return s.fast_claim(node.extra); }

            bool await_suspend(
                std::experimental::coroutine_handle&lt;&gt; handle)
            { return s.await_suspend(handle, node); }

            void await_resume()
            { s.await_resume(node); }

            ~awaiter() { s.destruct_node(node); }
        };
    };
}
</pre>
<p>The <code>awaitable_<wbr/>sync_<wbr/>object</code> is a wrapper around a <code>shared_<wbr/>ptr</code> of the <code>State</code>. The shared state is constructed by forwarding all of the <code>awaitable_<wbr/>sync_<wbr/>object</code> constructor parameters to the <code>State</code> constructor, so that you can construct the <code>State</code> object with any default initial state. For example, semaphores may want to be initialized with an initial token count and possibly also a maximum token count.</p>
<p>There is also a <code>make_<wbr/>awaiter</code> method for creating the awaiter with optional <code>extra_<wbr/>await_<wbr/>data</code>, if you need to pass additional context for a particular <code>await</code> operation.</p>
<p>And the last public method is the <code>co_await</code> operator which creates our custom-defined <code>awaiter</code>.</p>
<p>The protected methods are for the custom synchronization object to use as part of its implementation. The <code>get_<wbr/>state()</code> method lets the implementation access its own state. The <code>action_<wbr/>impl</code> forwards its parameters to the state’s <code>action_<wbr/>impl</code> method, which we discussed earlier.</p>
<p>The <code>awaiter</code> is generalized so that you can construct the extra data in the node. The <code>await_<wbr/>ready</code> tries to do a <code>fast_<wbr/>claim</code>, which might allow the caller to bypass suspension if it was able to claim the object immediately. The <code>await_<wbr/>suspend</code> method forwards to the state, which we discussed earlier. The <code>await_<wbr/>resume</code> method asks the <code>State</code> to clean up, and recall that the method sets the <code>handle</code> to null to indicate that the coroutine is no longer suspended. We use that fact in the awaiter’s destructor to detect the case where the coroutine is destroyed while suspended: In that case, the <code>handle</code> will still hold the coroutine’s continuation (which is being abandoned), and that tells us to unlink this coroutine from the list of waiters.</p>
<p>There is a race condition here, in the case that a coroutine is destroyed while a resumption is in flight, but as I noted earlier, this is a bug in the caller, so we don’t need to defend against it particularly hard. I chose to null out the <code>handle</code> in <code>await_<wbr/>resume</code> because that is more likely to be optimized out by the compiler, seeing as the awaiter’s destructor runs immediately after <code>await_<wbr/>resume</code>, which increases the likelihood that the compiler will be able to propagate the value into the awaiter’s destructor and realize that the code path is dead in the case of normal resumption.</p>
<p>Now, we could have nulled out the coroutine handle at many points in the lifetime of the awaiter. Why did I choose to do it in <code>await_<wbr/>resume</code>? Let’s sketch out the various possible fates of the awaiter:</p>
<table border="0" cellpadding="3" cellspacing="0" class="cp3" style="border-collapse: collapse; text-align: center;">
<tbody>
<tr>
<td colspan="5" style="border: solid 1px black;">Awaiter constructed<br/>
<code>handle = nullptr;</code></td>
</tr>
<tr>
<td>↓</td>
<td> </td>
<td>↓</td>
<td> </td>
<td> </td>
</tr>
<tr>
<td rowspan="7" style="border: solid 1px black;">No suspension</td>
<td> </td>
<td style="border: solid 1px black;">Suspended<br/>
<code>await_suspend</code><br/>
<code>handle = coroutine;</code></td>
<td> </td>
<td> </td>
</tr>
<tr>
<td> </td>
<td>↓</td>
<td>↘︎</td>
<td> </td>
</tr>
<tr>
<td> </td>
<td style="border: solid 1px black;">Resume<br/>
<code>resume_node</code></td>
<td> </td>
<td rowspan="5" style="border: solid 1px black;">Cancelled</td>
</tr>
<tr>
<td> </td>
<td>↓</td>
<td> </td>
</tr>
<tr>
<td> </td>
<td style="border: solid 1px black;">Resuming<br/>
<code>resume_node_callback</code></td>
<td> </td>
</tr>
<tr>
<td> </td>
<td>↓</td>
<td> </td>
</tr>
<tr>
<td> </td>
<td style="border: solid 1px black;">Resumed<br/>
<code>await_ready</code><br/>
<code>handle = nullptr;</code></td>
<td> </td>
</tr>
<tr>
<td>↓</td>
<td> </td>
<td>↓</td>
<td> </td>
<td>↓</td>
</tr>
<tr>
<td colspan="5" style="border: solid 1px black;">Awaiter destructed</td>
</tr>
</tbody>
</table>
<p>In the case where the coroutine doesn’t suspend because it was able to claim the synchronization object, the <code>handle</code> starts out as <code>nullptr</code> and stays that way until it is destructed. I’m hoping the optimizer can observe that the <code>handle</code> is not modified through this non-suspending path. The destructor’s call to <code>destruct_<wbr/>node</code> will therefore do nothing, since it does work only if the handle is non-null, and can consequently be completely optimized out.</p>
<p>In the case where the coroutine is cancelled, the coroutine handle is set to a non-null value in <code>await_<wbr/>suspend</code> after the coroutine has suspended. When the coroutine is cancelled, the coroutine’s destructor destructs the awaiter, and at that point, the <code>destruct_<wbr/>node</code> observes a non-null handle and knows to unlink the node from the list of waiters.</p>
<p>The last case is the one down the middle, and it’s the most complicated one: The synchronization object cannot be claimed, so the <code>handle</code> gets set to the coroutine handle after the coroutine suspends. Later, some code signals the synchronization object, and it resumes all of the waiters. Eventually, we get to the <code>await_<wbr/>ready</code> which is called inside the now-resumed coroutine, and it sets the <code>handle</code> back to null to indicate that everything is back to normal. By setting the <code>handle</code> to null at the last moment before destruction, I’m hoping the optimizer can recognize that the destructor’s call to <code>destruct_<wbr/>node</code> will do nothing, since it does work only if the handle is non-null, and can be completely optimized out.</p>
<p>It looks like gcc 10.1 and the Microsoft Visual C++ 19.24 compiler both can take my hints, and they do do optimize out the <code>destruct_<wbr/>node</code> calls in the two cases I noted. So hooray for that.</p>
<p>Okay, that was a whirlwind tour of our little library for writing generic awaitable synchronization objects. I did mention that this version resumes coroutines synchronously. Next time, <a href="https://devblogs.microsoft.com/oldnewthing/20210311-00/?p=104949" title="Creating other types of synchronization objects that can be used with co_await, part 3: Parallel resumption"> we’ll make it resume coroutines on a thread pool</a>.</p>
<p>¹ We could defend against this by having <code>resume_<wbr/>list</code> make the node point to itself, so that if the race occurs, we don’t corrupt memory immediately. But really, all we are doing is delaying the corruption, because the resumption will try to resume a destroyed coroutine, which will corrupt memory in a different way. Maybe we should <code>std::terminate</code>.</p>


</body>